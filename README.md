# SAFT: Semantic-Aware Adversarial Fine-Tuning

Code repository for SAFT.

---
## Installation

### Prerequisites
- Python 3.8+
- CUDA 11.7+ or CUDA 12.x
- Conda (recommended)

### Step 1: Create Conda Environment
```bash
conda create -n SAFT python=3.8
conda activate SAFT
```

### Step 2: Install PyTorch
Install PyTorch with CUDA support (adjust CUDA version as needed):

```bash
# For CUDA 12.4
pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu124

# For CUDA 11.8
pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```
---

## Usage

### Training

#### TGA-ZSR Training (Baseline)
Train on TinyImageNet with single template prompt:

```bash
python main.py --Method "TGA-ZSR" --ncaps 0 --batch_size 128 --epochs 10
```

#### SAFT Training (SAFT-L)
Train with multiple semantic captions:

```bash
python main.py --ncaps 5 --batch_size 128 --epochs 10
```

#### SAFT Training (SAFT-M)
Use MLLM-generated descriptions:

```bash
python main.py --ncaps 5 --batch_size 128 --epochs 10 --MLLM
```

### Evaluation
A SAFT-L checkpoint fine-tuned on Tiny-ImageNet is provided at [this link](https://drive.google.com/drive/folders/14_CwrrAe1_otRRysMf8bmXruBl-6gxpD?usp=sharing). To evaluate, copy the checkpoint directory into `./save/models/` and run the following command:

```bash
python main.py --ncaps 5 --seed 3 --checkpoint
```

Otherwise, if you have trained your own checkpoints:
#### Evaluation on TGA-ZSR (Baseline)

```bash
python main.py --Method "TGA-ZSR" --ncaps 0 --checkpoint
```

#### Evaluation on SAFT-L

```bash
python main.py --ncaps 5 --checkpoint
```

#### Evaluation on SAFT-M

```bash
python main.py --ncaps 5 --MLLM --checkpoint 
```

---
## Experiment Tracking
The code uses **Weights & Biases (wandb)** for experiment tracking by default.

- Set `--wandb True` to enable logging (default)
- Set `--wandb False` to disable logging
- Logs include: training loss, clean/adversarial accuracy, hyperparameters

---

## Output
### Saved Models
Checkpoints are saved to `./save/models/{experiment_name}/`:

```
model_final_seed{index}.pth.tar
```
---

## Project Structure
```
SAFT/
├── main.py                  # Main entry point
├── config.py                # Configuration and argument parsing
├── training.py              # Training logic and TrainingManager
├── model_setup.py           # Model initialization and setup
├── validation.py            # Validation and adversarial evaluation
├── helper.py                # Utility functions (data loading, text prompts, etc.)
├── attacks/                 # Adversarial attack implementations
│   ├── pgd_attack.py       # PGD attack
│   ├── auto_attack.py      # AutoAttack
│   └── cw_attack.py        # C&W attack
├── models/                  # CLIP model
├── prompts/                 # Text prompt datasets
│   ├── cupl.json                                    # ImageNet descriptions generated by LLM
│   ├── imagenet_descriptions_by_category.json       # ImageNet descriptions generated by MLLM
│   └── tinyimagenet_descriptions_by_category.json   # TinyImageNet descriptions generated by MLLM
├── val_datasets/            # Validation dataset loaders
├── utils/                   # Utility files (class name mappings, etc.)
├── requirements.txt         # Python dependencies
└── README.md               # This file
```
---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---
